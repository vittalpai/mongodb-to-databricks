name=s3-sink-connector
connector.class=io.confluent.connect.s3.S3SinkConnector
tasks.max=1
topics=<DB.COLLECTION>
s3.region=<S3-REGION>
s3.bucket.name=<S3-BUCKET-NAME>
s3.part.size=5242880
flush.size=200
storage.class=io.confluent.connect.s3.storage.S3Storage
format.class=io.confluent.connect.s3.format.json.JsonFormat
schema.generator.class=io.confluent.connect.storage.hive.schema.DefaultSchemaGenerator
partitioner.class=io.confluent.connect.storage.partitioner.TimeBasedPartitioner
path.format='date'=YYYY-MM-dd/'hour'=HH/'MM'=mm
locale=en
timezone=UTC
partition.duration.ms=60000
rotate.interval.ms=20000    
schema.compatibility=NONE
key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable=false